{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "extreme-finish",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "tweets_csv = Path('data/tweets_elonmusk_raw_FINAL.csv')\n",
    "tweets_df = pd.read_csv(tweets_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "stable-fantasy",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check Tweet counts with thousand differentiator (.) and (K)\n",
    "#WHERE only K - REPLACE with 3 zeros (000)\n",
    "#WHERE dot (.) and K - REMOVE dot (.) and REPLACE K with 2 zeros (00)\n",
    "#REPLACE M (million) with 6 zeros (000000)\n",
    "\n",
    "######\n",
    "######NOTE: THIS NEEDS TO BE REVISIT. IT APPEARS IT WILL REPLACE ALL K's WITH 00 FROM OTHER COLUMNS######\n",
    "######\n",
    "tweets_df.loc[(tweets_df.tweet_like_count.str.match('.*[K,k]') == True)] = tweets_df.loc[(tweets_df.tweet_like_count.str.match('.*[K,k]') == True)].replace('[K,k]','00', regex = True).replace('[.]','', regex = True)\n",
    "tweets_df.loc[(tweets_df.tweet_like_count.str.match('[K,k]') == True)] = tweets_df.loc[(tweets_df.tweet_like_count.str.match('[K,k]') == True)].replace('[K,k]','000', regex = True)\n",
    "tweets_df['tweet_like_count'] = tweets_df['tweet_like_count'].str.replace(r'M', '000000')\n",
    "\n",
    "tweets_df.loc[(tweets_df.tweet_retweet_count.str.match('.*[K,k]') == True)] = tweets_df.loc[(tweets_df.tweet_retweet_count.str.match('.*[K,k]') == True)].replace('[K,k]','00', regex = True).replace('[.]','', regex = True)\n",
    "tweets_df.loc[(tweets_df.tweet_retweet_count.str.match('[K,k]') == True)] = tweets_df.loc[(tweets_df.tweet_retweet_count.str.match('[K,k]') == True)].replace('[K,k]','000', regex = True)\n",
    "\n",
    "tweets_df.loc[(tweets_df.tweet_reply_count.str.match('.*[K,k]') == True)] = tweets_df.loc[(tweets_df.tweet_reply_count.str.match('.*[K,k]') == True)].replace('[K,k]','00', regex = True).replace('[.]','', regex = True)\n",
    "tweets_df.loc[(tweets_df.tweet_reply_count.str.match('[K,k]') == True)] = tweets_df.loc[(tweets_df.tweet_reply_count.str.match('[K,k]') == True)].replace('[K,k]','000', regex = True)\n",
    "######\n",
    "######END\n",
    "######\n",
    "\n",
    "\n",
    "#Tweets without content such as images will be filled with 'no content'\n",
    "#reply, retweets and likes will be populated with 0 if not available\n",
    "tweets_df['tweet_content'] = tweets_df['tweet_content'].fillna('NO CONTENT')\n",
    "tweets_df['tweet_reply_count'] = tweets_df['tweet_reply_count'].fillna('0')\n",
    "tweets_df['tweet_retweet_count'] = tweets_df['tweet_retweet_count'].fillna('0')\n",
    "tweets_df['tweet_like_count'] = tweets_df['tweet_like_count'].fillna('0')\n",
    "\n",
    "#convert counts into integer\n",
    "tweets_df['tweet_reply_count'] = tweets_df['tweet_reply_count'].astype(int)\n",
    "tweets_df['tweet_retweet_count'] = tweets_df['tweet_retweet_count'].astype(int)\n",
    "tweets_df['tweet_like_count'] = tweets_df['tweet_like_count'].astype(int)\n",
    "\n",
    "\n",
    "#SET the tweet content lower case for further comparison\n",
    "tweets_df['tweet_content'] = tweets_df['tweet_content'].str.lower()\n",
    "\n",
    "#Clean Timestamp of Tweets\n",
    "tweets_df['tweet_date'] = tweets_df['tweet_date'].str.replace(r'\\.', '') #remove dot (.)\n",
    "tweets_df['tweet_date'] = tweets_df['tweet_date'].str.replace(r'000Z$', '') #remove last 4 chars\n",
    "tweets_df['tweet_date'] = pd.to_datetime(tweets_df['tweet_date'], format='%Y-%m-%dT%H:%M:%S') #converting data into Datetime\n",
    "\n",
    "#Tweets Date has been UTC timezone by default and needed to transform to ETC\n",
    "tweets_df.tweet_date = tweets_df.tweet_date.dt.tz_localize('UTC').dt.tz_convert('US/Eastern')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "incorporated-essay",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save all Tweets\n",
    "\n",
    "tweets_df.to_csv('data/tweets_elonmusk_all_CLEAN.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "attended-afternoon",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FILTER FOR KEY WORDS\n",
    "includeKeywords = [\n",
    "    'doge', \n",
    "    'bitcoin', \n",
    "    'crypto', \n",
    "    'coin', \n",
    "    'dogecoin', \n",
    "    'eth', \n",
    "    'btc', \n",
    "    'currency', \n",
    "    'cryptocurrency', \n",
    "    'dogecoin',\n",
    "    'ethereum',\n",
    "    'bloc00chain',\n",
    "    'coinbase'\n",
    "    'ripple',\n",
    "    'bitcoincash',\n",
    "    'xrp'\n",
    "]\n",
    "\n",
    "#.stack to make tweets_df a Series and enable us to use the pandas.Series.str accessor functions\n",
    "#.str.contains with '|'.join(includeKeywords)\n",
    "#.any with argument level=0 because we added a level to the index when we stacked\n",
    "\n",
    "tweets_df = tweets_df[tweets_df.stack().str.contains('|'.join(includeKeywords)).any(level=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "chronic-paragraph",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save filtered Tweets\n",
    "\n",
    "tweets_df.to_csv('data/tweets_elonmusk_crypto_CLEAN.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
